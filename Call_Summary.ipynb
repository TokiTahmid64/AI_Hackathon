{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeadDkMiISin"
      },
      "source": [
        "# Gemini API: Quickstart with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEXQ3OwKIa-O"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/tutorials/python_quickstart\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on Google AI</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOxMUKTxR-_j"
      },
      "source": [
        "This quickstart demonstrates how to use the Python SDK for the Gemini API, which gives you access to Google's Gemini large language models. In this quickstart, you will learn how to:\n",
        "\n",
        "1. Set up your development environment and API access to use Gemini.\n",
        "2. Generate text responses from text inputs.\n",
        "3. Generate text responses from multimodal inputs (text and images).\n",
        "4. Use Gemini for multi-turn conversations (chat).\n",
        "5. Use embeddings for large language models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9__zr1nSBpE"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "You can run this quickstart in [Google Colab](https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb), which runs this notebook directly in the browser and does not require additional environment configuration.\n",
        "\n",
        "Alternatively, to complete this quickstart locally, ensure that your development environment meets the following requirements:\n",
        "\n",
        "-  Python 3.9+\n",
        "-  An installation of `jupyter` to run the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFPBKLapSCkM"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFNV1e3ASJha"
      },
      "source": [
        "### Install the Python SDK\n",
        "\n",
        "The Python SDK for the Gemini API, is contained in the [`google-generativeai`](https://pypi.org/project/google-generativeai/) package. Install the dependency using pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OEoeosRTv-5",
        "outputId": "3d133385-a4da-40c2-ca61-aa3e7317218c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m133.1/137.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCFF5VSTbcAR"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRC2HngneEeQ"
      },
      "source": [
        "Import the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS9l5igubpHO"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d10c38a5c91f"
      },
      "outputs": [],
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHYFrFPjSGNq"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "\n",
        "<a class=\"button button-primary\" href=\"https://makersuite.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHhsUxDTdw0W"
      },
      "source": [
        "In Colab, add the key to the secrets manager under the \"🔑\" in the left panel. Give it the name `GOOGLE_API_KEY`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmSlTHXxb5pV"
      },
      "source": [
        "Once you have the API key, pass it to the SDK. You can do this in two ways:\n",
        "\n",
        "* Put the key in the `GOOGLE_API_KEY` environment variable (the SDK will automatically pick it up from there).\n",
        "* Pass the key to `genai.configure(api_key=...)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab9ASynfcIZn"
      },
      "outputs": [],
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ssbTMNVSMd-"
      },
      "source": [
        "## List models\n",
        "\n",
        "Now you're ready to call the Gemini API. Use `list_models` to see the available Gemini models:\n",
        "\n",
        "* `gemini-pro`: optimized for text-only prompts.\n",
        "* `gemini-pro-vision`: optimized for text-and-images prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvvWFy08e5c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "91963f6d-a78a-40e9-f986-daad2ff05574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTl5NjtrhA0J"
      },
      "source": [
        "Note: For detailed information about the available models, including their capabilities and rate limits, see [Gemini models](https://ai.google.dev/models/gemini). There are options for requesting [rate limit increases](https://ai.google.dev/docs/increase_quota). The rate limit for Gemini-Pro models is 60 requests per minute (RPM).\n",
        "\n",
        "The `genai` package also supports the PaLM  family of models, but only the Gemini models support the generic, multimodal capabilities of the `generateContent` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZfoK3I3hu6V"
      },
      "source": [
        "## Generate text from text inputs\n",
        "\n",
        "For text-only prompts, use the `gemini-pro` model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bcfnGEviwTI"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR_2A_sxk8sK"
      },
      "source": [
        "The `generate_content` method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. The available models only support text and images as input, and text as output.\n",
        "\n",
        "In the simplest case, you can pass a prompt string to the <a href=\"https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content\"><code>GenerativeModel.generate_content</code></a> method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "he-OfzBbhACQ",
        "outputId": "af66c41a-ce6f-4a5b-e6a0-ce8c7a46d73e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 320 ms, sys: 33.1 ms, total: 353 ms\n",
            "Wall time: 23 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "string=\"\"\"\n",
        "Summarize the below text in Bangla  ( A phonecall). Provide key points of this conversation:\n",
        "----------------------------------------------------------------------------------------------------\n",
        "SPEAKER_00: হ্যালো মিরাজ।\n",
        "SPEAKER_01: হ্যাঁ তামিম ভাই। আসালামালাইকুম।\n",
        "SPEAKER_00: কী অবস্থায় এটা কেমন আছে?\n",
        "SPEAKER_01: এই তো আল্লাহ মুজিবুল্লাহ ভাই আপনি কেমন আছেন?\n",
        "SPEAKER_00: কেমন থাকি রে তুই? এই মুশফিকের কোনো কাজ করছিস রে মিরাজ?\n",
        "SPEAKER_01: ভাই শুনলাম আমিও। সে জিনিসটা ঠিক আছে। এখন কী করবেন?\n",
        "SPEAKER_00: লাস্টে আমাদের ফাইনালের পরে আমাদের মিটিংয়ে কী কথা হয়েছে? আমি তোর ওই সময় একটা কথা বলছিলাম না যে, আমরা চেষ্টা করব যে সত্তর থেকে আশি পারসেন্ট আমরা যেরকম সেইম টিম থাকতে পারি। আর এই কথার বেইজিতও ছিল তুই মুশফিকার সবসময় ঠিক না। মুশফিক আমার জন্য একটা ইম্পটেন্ট একজন ছিল। সে সে করছেটা কি? শুন সে আমার সাথে তো কথা বলেই নেই। বলে নেই। সে বলে এখন আলাদা একটা টিম বানাচ্ছে।\n",
        "SPEAKER_01: আমি একটু হালকা একটু শুনেছিলাম বাটা হান্ডেট পারসেন্ট কনফার্ম ছিলাম না। বাট আপনি এখন যেটা বললেন, আমি তো এখন হান্ডেট পার্সেন্ট শিরোলাম যে ভাই মনে হয়।\n",
        "SPEAKER_00: বিশ্ববিদ্যালয়ের মধ্যে একটি বিদ্যালয়ের মধ্যে একটি বিদ্যালয়ের মধ্যে একটি বিদ্যালয়ের।\n",
        "SPEAKER_01: আলাদা টিম বানাচ্ছে।\n",
        "SPEAKER_00: তুই দেখছস আমি ওরে কি ধরনের ফ্রিডম দিছি পুরা টিমে। আমি ওরে দায়িত্ব দিছি পুরা টিম চালানোর। খেলা শেষ হয়েছে। খেলা শেষে আমি সবচেয়ে বেশি ওরে প্রেস করছি। আমি এখন পর্যন্ত ওরে প্রেস থাকি যে সে পুরা টিমটা হ্যান্ডেল করছে। তার কন্ট্রোবেশনটা কত বেশি। সে এই মুহূর্তে আমাকে এরকম মাঝপথে ছেড়ে যাওয়াটা কি উচিত ছিল?\n",
        "SPEAKER_01: এখন কী করবেন ভাই? এখন ভাই গেছে। এখন সে তো আপনারই ফ্রেন্ড।\n",
        "SPEAKER_00: এখন আসলে তো তোদের সাথে নাই। খেলি না তো ন্যাশনাল টিমে এখন অনেকের অনেক ভাবটা বেড়ে গেছে। এটা হল সমস্যা। ঠিক আছে। কারণ হল যে, এখন তোদের সাথে ক্যাপ্টেন থাকলে, ক্যাপ্টেন থাকলে তো এরকম আর তোরা করতে পারতি না। এখন আমার দাম নেই। এখন দাম কমে যাচ্ছে দেখে তোরা এসব করতেছে।\n",
        "SPEAKER_01: ভাই শোনেন রাগ করেন না প্লিজ। কারণ কি ভাই আপনি তো জানেন মুশফিক বা সম্পর্কে সে তো একটু ইমোশনাল। হয়তো ইমোশনাল হয়ে পড়ে যায়।\n",
        "SPEAKER_00: একবার আমাকে অ্যাটলিস বলত, চলে যাওয়ার আগে অ্যাটলিস। তখন তো আমার একটু শান্তি হইত। যেন আগে অ্যাটলিস বলেই গেছে, অসুবিধা না মিরাজ। সময় আমারও তো আসবে। পৃথিবী গোল। কিন্তু শুনে রাখ মিরাজ, একটা কথা শুন, পৃথিবীর গোল। আজকে তুই ওই সাইট, আমি এ সাইট। কালকে আমিও সাইডে বসব। তুই এ সাইডে আসবি। ভুলে যাস না। আর রোডা তোর বড় ভাইরেও বলে দিস।\n",
        "SPEAKER_01: ভাই আপনারা রাগ করেন না। ঠান্ডা হন ভাই।\n",
        "SPEAKER_00: তুই দেখ আমি কি করি। আমি কথা করব না তোর সাথে এ ব্যাপারে কথা করব। জিনিসটা কাজটাও কোনোভাবেই ঠিক করেনি।\n",
        "SPEAKER_01: থান্ডার।\n",
        "SPEAKER_00: ঠিক করা।\n",
        "SPEAKER_01: দরকার নাই।\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbrR-n_qlpFd"
      },
      "source": [
        "In simple cases, the `response.text` accessor is all you need. To display formatted Markdown text, use the `to_markdown` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-zBkueElVEO",
        "outputId": "01ac4e60-f867-4984-c8a2-89b689a3ac62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **ফোন কলের সারাংশ**\n> \n> **মূল পয়েন্টসমূহ:**\n> \n> * মিরাজ মুশফিকের সাথে কাজ না করার বিষয়ে আলোচনা করছে।\n> * মুশফিক আলাদা দল গড়ছে বলে মিরাজের অভিযোগ।\n> * মিরাজ মনে করছে মুশফিক অনুচিতভাবে দল ত্যাগ করেছে।\n> * মিরাজ জাতীয় দলের অন্যান্য খেলোয়াড়দের অসন্তুষ্টি এবং সম্মানের অভাব সম্পর্কে কথা বলছে।\n> * মিরাজ মিরাজকে সতর্ক করেছে যে ভবিষ্যতে রোল পরিবর্তন হতে পারে।\n> \n> **বাংলায় সারাংশ:**\n> \n> টামিম: হ্যালো মিরাজ।\n> \n> মিরাজ: হ্যাঁ ভাই, আসসালামু আলাইকুম।\n> \n> টামিম: কেমন আছো?\n> \n> মিরাজ: আল্লাহর রহমতে ভালো, আপনি কেমন আছেন?\n> \n> টামিম: কেমন থাকবোরে তুমি? মুশফিকের সাথে কাজ করছো এখন?\n> \n> মিরাজ: ভাই, শুনেছি। বিষয়টা সত্যি। এখন কী করা যাবে?\n> \n> টামিম: আমাদের আগের মিটিংয়ে কী কথা হয়েছিল মনে আছে? আমরা বলেছিলাম যে, সত্তর থেকে আশি শতাংশ আগের দলটাকে রাখতে চাই। আর এর কারণ ছিল মুশফিকের অভাব। মুশফিক আমার জন্য খুব গুরুত্বপূর্ণ ছিল। কিন্তু সে এখন কী করছে? সে আমার সাথে কথাও রাখছে না। সে বলছে আলাদা দল তৈরি করবে।\n> \n> মিরাজ: আমি কিছুটা শুনেছিলাম কিন্তু নিশ্চিত ছিলাম না। কিন্তু আপনি এখন যেটা বললেন, আমি এখন শতভাগ নিশ্চিত যে ভাই, হয়তো মনে হচ্ছে।\n> \n> টামিম: একটু একটু করে সবকিছু হবে।\n> \n> মিরাজ: আলাদা দল বানাচ্ছে?\n> \n> টামিম: তুমি দেখেছো আমি কী রকম স্বাধীনতা দিয়েছি পুরো দলজুড়ে। আমি তাকে সম্পূর্ণ দল পরিচালনার দায়িত্ব দিয়েছি৷ খেলা শেষ হয়ে গেছে৷ খেলা শেষে আমি সবচেয়ে বেশি তাকে চাপ দিচ্ছি৷ আমি এখনও তাকে চাপে রাখি যে সে পুরো দলটাকে নিয়ন্ত্রণ করছে৷ তার কতটা নিয়ন্ত্রণ আছে৷ এই মুহূর্তে আমাকে এভাবে মাঝপথে ফেলে যাওয়াটা কি তার উচিত ছিল?\n> \n> মিরাজ: এখন কী করবেন ভাই? এখন ভাই গেছেন৷ সে আপনার বন্ধু।\n> \n> টামিম: এখন তোমাদের সাথে নেই৷ জাতীয় দলে খেলি না, এখন অনেকের অনেক অনুভূতি বেড়ে গেছে৷ এটাই সমস্যা৷ কারণ, এখন তোমাদের সাথে ক্যাপ্টেন থাকলে, তোমরা এমনটা করতে পারবে না৷ এখন আমার কোনো মূল্য নেই৷ এখন মূল্য কমে যাচ্ছে দেখে তোমরা এসব করছো৷\n> \n> মিরাজ: ভাই, দয়া করে রাগ করবেন না৷ কারণ ভাই, আপনি জানেন মুশফিক একটু বেশি আবেগপ্রবণ৷ হয়তো আবেগে পড়ে যায়৷\n> \n> টামিম: আগে আমাকে অ্যাটলিস বলত, চলে যাওয়ার আগে অ্যাটলিস৷ তখন আমার কিছুটা শান্তি হতো। যেন আগে অ্যাটলিস বলেই গেছে, অসুবিধা নেই মিরাজ, সময় আমারও আসবে৷ পৃথিবী গোল৷ কিন্তু মিরাজ, একটা কথা শোনো, পৃথিবী গোল৷ আজকে তুমি ওই পাশে, আমি এই পাশে৷ কালকে আমিও ওই পাশে বসব৷ তুমি এ পাশে আসবে৷ ভুলে যো না৷ আর রোদা তোমার বড় ভাইকেও বলে দিও৷\n> \n> মিরাজ: ভাই, আপনি রাগ করবেন না৷ শান্ত হোন ভাই৷\n> \n> টামিম: তুমি দেখো আমি কী করি৷ আমি তোমার সাথে কথা বলব না৷ এ ব্যাপারে কথা বলব৷ এই জিনিসটাও ঠিক করোনি৷\n> \n> মিরাজ: শান্ত হোন৷\n> \n> টামিম: ঠিক করতে হবে৷\n> \n> মিরাজ: দরকার নেই৷"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZPpoKMQoru8"
      },
      "source": [
        "If the API failed to return a result, use `GenerateContentRespose.prompt_feedback` to see if it was blocked due to safety concerns regarding the prompt."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "google": {
      "image_path": "/static/site-assets/images/docs/logo-python.svg",
      "keywords": [
        "examples",
        "gemini",
        "beginner",
        "googleai",
        "quickstart",
        "python",
        "text",
        "chat",
        "vision",
        "embed"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}